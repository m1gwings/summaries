---
marp: true
theme: summary
math: mathjax
---
# Turing 1950

<div class="author">

Cristiano Migali

</div>

## Summary

The article revolves around the question "Can machines think?".

In the first part of the article, the author tries to define better what he means with such question. One way is to begin with the definitions of _machine_ and _think_. But the usual definitions reflect only the normal use of the worlds. Then, answering to the question would become equivalent to a statistical survey.
Instead of attempting to find satisfactory definitions, the author substitute the question with another, which is less ambiguous, and then argues about the relevance of this second question.
To formulate the new question, it is necessary to introduce a game known as "the imitation game". It is played with three people, a man (A), a woman (B), and an interrogator (C) who may be of either sex. The interrogator stays in a room apart from the other two. The object of the game for the interrogator is to determine which of the other two is the man and which is the woman. He knows them by labels X and Y, and at the end of the game he says either "X is A and Y is B" or "X is B and Y is A". The interrogator is allowed to put questions to A and B. The objective of A in the game is to cause C to make the wrong identification. B, conversely, should help the interrogator. The idea of the author is to study what happens when we replace a machine with A in the game. If the machine has a level of performance similar or superior to the human, then we may argue that it is thinking. In order that tones of voice may not help the interrogator, the answers should be written, or better still, typed. 
According to the author, the question and answer method seems to be suitable for introducing almost any one of the fields of human endeavour that one wishes to include.

The second part of the article describes the kind of machines which, according to the author, should be the subject of the question. It is natural to permit every kind of engineering technique to be used in such machines. It also reasonable to allow the possibility that an engineer or team of engineers may construct a machine which works, but whose manner or operation cannot be satisfactorily described by its constructors because they have applied a method which is largely experimental. Finally, humans should be clearly excluded from the set of machines. It is difficult to frame a definition which satisfies these 3 criteria. Imagine if a team of engineers were able to "grow" a complete individual out of a single skin cell. To do so would be a feat of astonishing biological technique, but this clearly should not be regarded as "constructing a thinking machine". For this reason, it makes sense to exclude the possibility that every kind of technique in building a machine could be used. This is not a big deal since the interest in "thinking machines" regarded one particular kind of machine: the _digital computer_. The restriction appears at first sight very drastic. The author explains why this is not true.

---

The idea behind digital computers may be explained by saying that these machines are intended to carry out any operations which could be done by a human computer. The human computer is supposed to be following fixed rules; he has no authority to deviate from them in any detail. We may suppose that these rules are supplied in a book, which is altered whenever they are put on to a new job. They have also an unlimited supply of paper on which he does his calculations.
A _digital computer_ can usually be regarded as consisting of three parts:
1. store;
2. executive unit;
3. control.

The store is a store of information and corresponds to the human computer's paper, whether this is the paper on which he does his calculations or that on which his book of rules is printed.
The executive unit is the part which carries out the various individual operations involved in a calculation.
The "book of rules" supplied to the computer is replaced in the machine by a part of the store, It is then called the "table of instructions". It is the duty of the control to see that these instructions are obeyed correctly and in the right order.
The table of instructions should contain instruction of the kind "do ... and then move to instruction # ...". This kind of instructions allow to alter the flow of execution of the process executed by the computer, making it possible, for example, to repeat a sequence of operations over and over again until some conditions is fulfilled. The digital computer may be classified amongst the "discrete state machines". These are the machines which move by sudden jumps or clicks from one quite definite state to another. Strictly speaking there are no such machines. Everything really moves continuously. But there are many kinds of machine which can profitably be _thought of_ as being discrete state machines.
Digital computers have a very interesting property, not only they are a discrete state machine, they can also simulate any other discrete state machine, assuming they are provided with enough storage. For this reason, they are called _universal_ machines.
The new question, which replaces the original "Can machines think?", is then reframed as: "Lt us fix our attention on one particular digital computer C. Is is true that by modifying this computer to have an adequate storage, suitably increasing its speed of action, and providing it with an appropriate program, C can be made to play satisfactorily the part of A in the imitation game, the part of B being taken by a man?".
The author believes that in about fifty years of time it will be possible to programme computer, with a storage capacity of about $10^9$, to make them paly the imitation game so well that na average interrogator will not have more than $70 \%$ chance of making the right identification after five minutes of questioning. The author believes that the question "Can machines think?" is too meaningless to deserve discussion. Nevertheless he believes that at the end of the century the use of words and general educated opinion will have altered so much that one will be able to speak of machines thinking without expecting to be contradicted.

---

The author remarks that there is no reason for him to hide these beliefs. Indeed, the popular view that scientists proceed inexorably from well-established facts to well-established facts, never being influenced by any unproved conjecture, is quite mistaken. Provided it is made clear which are proved facts and which are conjectures, no harm can result. Conjectures are of great importance since they suggest useful lines of research.

In the third part of the article, the author lists possible objections to the new question.
1. _The Theological Objection_. Thinking is a function of man's immortal soul. God has given an immortal soul to every man and woman, but not to any other animal or to machines. Hence no animal or machine can think. The author says that he is unable to accept any part of this objection, but will attempt to reply in theological terms. According to the author, an argument like the one above implies a serious restriction on the omnipotence of the Almighty. It is admitted that there are certain things that He cannot do such as making one equal to two. But, if He would consider the circumstances suitable for conferring a soul to a machine, He could certainly do it using us as instruments of His will. We should not be irreverently usurping His power of creating souls, any more than we are in the procreation of children.

2. _The "Heads in the Sand" Objection_. The consequences of machines thinking would be too dreadful. Let us hope and believe that they cannot do so.
This argument is seldom expressed quite so openly as in the form above. But, according to the author, it affects most of use who think about it at all. We like to believe that Man is in some subtle way superior to the rest of the creation. It is best if he can be shown to be _necessarily_ superior, for then there is no danger of him losing his commanding position. The authors do not think that this argument is sufficiently substantial to require refutation.

3. _The Mathematical Objection_. There are a number of results of mathematical logic which can be used to show that there are limitations to the powers of discrete-state machines. The best known of these results is known as Godel's theorem, and shows that in any sufficiently powerful logical system, statements can be formulated which can neither be proved nor disproved withing the system, unless possibly the system itself is inconsistent. There are other similar results. One in particular refers directly to the limit of discrete state machines, whereas others can only be used in a comparatively indirect argument.
The result in question refers to a type of machine which is essentially a digital computer with an infinite capacity. It states that there are certain things that such a machine cannot do.
The short answer to this argument is that although it is established that there are limitations to the powers of any particular machine, it has only been stated, without any sort of proof, that no such limitations apply to the human intellect.

---

4. _The Argument from Consciousness_. According to the most extreme form of this view the only way by which one could be sure that a machine thinks is to _be_ the machine and to feel oneself thinking. One could then describe these feelings to the world, but of course no one would be justified in taking any notice. Likewise according to this view the only way to know what a _man_ thinks is to be that particular man. Instead of arguing continually over this point it is usual to have the polite convention that everyone thinks.

5. _Arguments from Various Disabilities_. These arguments take the form, "I grant you that you can make machines do all the things you have mentioned but you will never be able to make one to do X". Numerous features X are suggested, like _be kind_, _resourceful_, _beautiful_, _friendly_, ... . No support is usually offered for these statements. The author believes they are mostly founded on the principle of scientific induction. A man has seen thousands of machines in his lifetime. From what he sees of them he draws a number of general conclusions. They are ugly, each is designed for a very limited purpose, when required for a minutely different purpose they are useless, the variety of behavior of any one of them is very small, etc. . One very curious claim, according to the author, is the one that states that "machines cannot make mistakes". The author then explains better this criticism in terms of the imitation game. It is claimed that the interrogator could distinguish the machine from the man simply by setting them a number of problems in arithmetic. The machine would be unmasked because of its deadly accuracy. The reply tot his is simple. The machine programmed for paying the game, would not attempt to give the _right_ answers to the arithmetic problems. It would deliberately introduce mistakes in a manner calculated to confuse the interrogator. A mechanical fault would probably show itself through an unsuitable decision as to what sort of mistake to make in the arithmetic. According to the author, this criticism depends on a confusion between two kinds of mistake: the "errors of functioning" and the "errors of conclusions". Errors of functioning are due to some mechanical or electrical fault which causes the machine to behave otherwise that it was designed to do. In philosophical discussions one likes to ignore the possibility os such errors; one is therefore discussing "abstract machines". These abstract machines are mathematical functions rather than physical objects.  By definition they are incapable of errors of functioning.
In this sense, we can truly say that "machines can never make mistakes". Errors of conclusions can only arise when some meaning is attached to the output signals from the machine. The machine might, for instance, type out mathematical equations, or sentences in English. When a false proposition is typed we say that the machine has committed an error of conclusion. There is clearly no reason at all for saying that a machine cannot make this kind of mistake. It might do nothing but type out repeatedly "0 = 1". To take a less perverse example, it might have some method for drawing conclusions by scientific induction. We must expect such a method to lead occasionally to erroneous results.

---

6. _Lady Lovelace's Objection_. Lady Lovelace stated the following regarding Babbage's Analytical Engine: "The Analytical Engine has no pretensions to _originate_ anything. It can do _whatever we know how to order it to perform_". However, it is important to notice, that this does not imply that it may not be possible to construct electronic equipment which will "think for itself", or in which, one could set up a "conditioned reflex" which would serve as a basis for "learning". A variant of Lady Lovelace's objection states that a machine can "never do anything really new". This may be parried for a moment with the saw, "There is nothing new under the sun". The view that machines cannot give rise to surprise is due, according to the author, to a fallacy to which philosophers and mathematicians are particularly subject. This is the assumption that as soon as a fact is presented to a mind all consequences of that fact spring into the mind simultaneously with it. A natural consequence is that one then assumes that there is no virtue in the mere working out of consequences from data and general principles.

7. _Argument from Continuity in the Nervous System_. The nervous system is certainly not a discrete-state machine. It is true that a discrete-state machine must be different from a continuous machine. But if we adhere to the conditions of the imitation game, the interrogator will not be able to take any advantage on this difference. In a question and answer setting, a discrete-state machine can simulate the behavior of a continuous-state machine.

8. _The Arguments from Informality of Behavior_. It is not possible to produce a set of rules purporting to describe what a man should do in every conceivable set of circumstances. First of all it is important to distinguish between "rules of conduct" and "laws of behavior". By "rules of conduct", the author means precepts such as "Stop if you see red lights", on which one can act, and of which one can be conscious. By "laws of behavior" the author means laws of nature as applied to human's body such as "if you pinch him he will squeak".  The objection can be rephrased as: since it is not possible to specify rules of conduct for every possible situation, these are not sufficient to explain human behavior. Hence, since humans do not just follow rules of conduct, they are not machines.
The point is that this statement stops being obviously true when we replace rule of conducts with laws of behavior. Maybe there are laws of behavior which explain every action a human takes.

9. _The Argument from Extra-Sensory Perception_. Extra-sensory perceptions comprehend: telepathy, clairvoyance, precognition, and psycho-kinesis. The author states that these disturbing phenomena have "overwhelming statistical evidence" (at least for telepathy).
Many scientific theories seem to remain workable in practice in spite of clashing with E.S.P. . The issue is that, if E.S.P. were a thing, they could play an important role in the imitation game
If the witness is a man who is good as a telepathic receiver, the interrogator can ask questions like "What suit does the card in my right hand belong to?".  

---

> The man by telepathy or clairvoyance gives the right answer more than 1/4th of the times, while the machine would have to guess randomly. Thus the investigator would be able to discern the human from the machine.

In the last part of the article, the author proposes a general principle by which a machine capable of doing well in the imitation game could be programmed. The idea comes from trying to understand the factors that determine the state of an adult mind. They are three:
> a. The initial state of the mind, say at birth.
b. The education to which it has been subjected.
c. Other experience, not to be described as education, to which it has been subjected. 

The idea is: instead of trying to produce a program to simulate the adult mind, it may be easier to build one which simulated a child mind. Then the machine would be subject to an appropriate course of education, and we would obtain an adult mind. The hope is that there is so little mechanism in the child brain that it can be easily programmed. The amount of work necessary for education can be assumed to be the same as for humans. The problem is thus divided in two parts: the child program, and the education process, which are tightly coupled. The development process could be regarded as an evolution process in which child program and education processes are tested, modified to get improvement, and then tested again. The hope is that, the experiment, through the exercise of intelligence, should be able to speed up this evolution process since they are not restricted to trying random mutations. One approach could be the usage of reward and punishment signal to teach to the machine "good" and "bad" behavior. This signal should not be the only channel of communication, having such low expressiveness. There should be another "unemotional" channel through which we can communicate with the machine in an expressive enough symbolic language.
