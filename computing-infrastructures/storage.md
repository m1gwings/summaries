---
marp: true
theme: summary
math: mathjax
---
# Storage

<div class="author">

Cristiano Migali
(_adapted from the slides of Prof. Manuel Roveri_)

</div>

<style>
section {
    font-size: x-large;
}

.definition {
    padding-left: 0.5cm;
    padding-right: 0.5cm;
    background: var(--algorithms);
    border-radius: 0.5cm;
    border-style: solid;
    border-color: var(--text);
    border-width: 3pt;
    text-align: justify;
}
</style>

## Trends

The growth of the "_Global Datasphere_" (the volume of all the data created in the world) in the last 15 years has been _exponential_. Between 80s and 90s most of the data was generated by humans. Nowadays machines generate data at an unprecedented rate.
Along with this growth, we can observe a shift to centralized storage (storing data in the cloud) because of the ease of maintenance for the consumer.
Storage technology is (_still_) **dominated by HDDs**, even though the **fraction** of data **stored** in **SSD** devices is **growing**. A (_almost_) constant fraction of data is (**_still_**) stored in **tapes**.

There are also some hybrid HDD+SSD solutions:
- some large storage servers use _SSD_ as a cache for several _HDDs_;
- some HDD manufacturers produce **Solid State Hybrid Disks** (**SSHDs**) that combine a _small SSD_ with a _large HDD_ is a single unit.

---

## Disk abstraction

_Disks_ are seen by the OS as a **collection of data blocks** that can be _read or written independently_. To allow the ordering/management between them, each block is characterized by a unique numerical address called **Logical Block Address** (**LBA**).
Typically the OS _groups blocks_ into **clusters** to simplify the access to the disk. They are the _minimal unit_ the OS can read from ro write to a disk. Clusters' size ranges from 1 _sector_ (_see later_) (512 B) to 128 sectors (64 KiB).

### What's inside clusters?

We can distinguish between _4 types of clusters_ according to their _content_ (_and position_).
- Fixed position, meta-data clusters: are needed to bootstrap the file system (_locate the variable position meta data clusters_).
- Variable position, meta-data clusters: hold the folder structure.
- File data clusters: store the actual files' content.
- Unused space: they are clusters which can be used to store new files and folders.

In particular **meta-data clusters contain**:
- file names;
- directory structures and symbolic links;

---

- file size and file type;
- creation, modification, and last access dates of files;
- security information (owner, access lists, ...);
- **the LBA where the file content can be located on the disk**.

### Operating on disks
#### Reading

**Reading a file** requires to:
1. Access the meta-data to locate its blocks.
2. Access the blocks to read its content.

#### Writing

**Writing a file** requires to:
1. Access the meta-data to locate free space.
2. Write the data in the assigned block.

#### Deleting

**Deleting a file** requires to:
1. (_Just_) Update the meta-data to mark the blocks where the file was stored as free. 

---

**Remark**: deleting a file never actually deletes the data on the disk. When a new file will be written on the same clusters, the old data will be replaced by the new one.

### Disks fragmentation

#### Internal fragmentation

Since the file system can only access clusters, the _real occupation_ of space _by a file_ on the disk is always a _multiple of the cluster size_.
In particular: let $s$ be the file size, $c$ be the cluster size, $a$ be the actual size of the file on disk. Then:
$$
a = c \left\lceil \frac{s}{c} \right\rceil .
$$
The quantity $w = a - s$ is **wasted disk space** due to the organization of the file into clusters. This waste of space is called **internal fragmentation** of files.

#### External fragmentation

As the life of the disk evolves there might be not enough space to store a file in contiguous clusters. In this case the file is split into smaller chunks that are stored in the free clusters spread over the disk.
The effect of splitting a file into non-contiguous clusters is called **external fragmentation**.

---

## Devices
### Hard Disk Drive (HDD)

An **HDD** is a data storage device using rotated disks coated with magnetic material. Data is read and written in a _random-access_ manner, meaning that individual blocks of data can be stored and retrieved in any order.

#### Anatomy of a HDD

The rotating disks on which the HDD stores the data are known as **platters**: they are of equal radius, concentric, and vertically stacked on an axis known as **spindle**. Each platter is split in a fixed number of circular crowns, all with the same difference between external and internal radii, known as **tracks**. The set of tracks on different platters which have the same internal (and hence external) radius (i.e. they are one on top of the other) form a **cylinder**.
Each platter is split in a fixed number of circular sectors, all defined by the same angle; the intersection between a circular sector and a track on the same platter define a **sector**. Sectors are the _minimal units_ that can be written or read from an HDD. They usually allow to store 512 B or 4096 B. A _write to a single sector_ is _atomic_. _Multiple sectors writes_ instead can be interrupted (failing), we call these **torn writes**.

---

For each platter there is a **read-write head** which allows the storage and retrieval of data from sectors; the heads are mounted on an actuated arm which allows to place them on top of the desired track.
Finally, also the spindle is actuated to make the platters spin at a constant rate, measured in Revolutions Per Minute (RPM).

#### Caching for a HDD

Many disks incorporate caches, known as **track buffers**. Usually these are implemented through small amounts of RAM (8, 16, or 32 MiB). Flash memories are used instead to have persistent caching.

When _reading_, caching allows to reduce the delays.

When _writing_ we distinguish two different behaviors.
- **Write back cache**: the drive reports that writes are _complete after they have been cached_. This approach allows to reduce also write delays, but can be dangerous when using non-persistent caching, since, if power goes off, we would loose the cached data which hasn't been written to disk yet.
- **Write through cache**: the drive reports that writes are _complete after they have been written to the disk (and to the cache)_.

---

#### Operations delay for a HDD

The **total delay** of operations performed on a HDD is the sum of _4 components_:
1. **Rotational delay**: it is the time required to rotate the platter as to place the desired sector under the read head, _assuming that the head is on the right track_.
2. **Seek delay**: it is the time required to move the read head to the desired track;
3. **Transfer time**: it is the time required by the actual reading or writing of the desired amount of bytes;
4. **Controller overhead**: it is the overhead due to requests management.

**Remark**: sectors are numbered in such a way that successive sectors which are on the same platter but on different tracks are _skewed_ to take into account the angle by which the platters rotate during the seek delay of moving the head from one track to the adjacent one. This makes sequential reads and writes more efficient.

##### Rotational delay

We call **full rotation delay** $R$ the time required for a full revolution of the platters. Said $\omega$ the platters angular velocity in RPMs,
$$
R = \frac{1 \text{ revolution}}{\omega} \text{ [ minutes ]}.
$$

---

We can make a conservative approximation of the rotational delay by considering the case in which the desired track is on the opposite side of the platter w.r.t. the head. In such a case we have two make an half revolution of the platter, that is:
$$
T_{\text{rotation}} = \frac{R}{2}.
$$

##### Seek delay

The seek delay is NOT linear w.r.t. the number of tracks the head has to traverse.
Indeed the movement of the head during seek is composed of 4 phases:
- Acceleration;
- Coasting (_at constant speed_);
- Deceleration;
- Settling.

In practice a rough approximation of the average seek delay is obtained by dividing by 3 the time it takes to move the head from the outermost to the innermost track (_or vice-versa_), which we denote with $T_{\text{seek (MAX)}}$. That is:
$$
T_{\text{seek (AVG)}} \approx \frac{T_{\text{seek (MAX)}}}{3}.
$$

---

##### Transfer time

It is the time during which the data is either read from or written to the surface. It includes the time for the head to pass on the sectors. Hence it depends on the _revolution speed_ and on the _storage density_.

##### Service time and response time of an HDD

Through the quantities that we have described we can calculate the **service time** and the **response time** (_see the summary on "Performance"_) of the disk.
$$
T_{\text{service}} = T_{\text{rotation}} + T_{\text{seek}} + T_{\text{transfer}} + T_{\text{controller}};
$$
$$
T_{\text{response}} = T_{\text{service}} + T_{\text{queue}}
$$
where $T_{\text{queue}}$ is the time that the read or write request stays in queue, waiting to be processed.

##### Service time for contiguous reads/writes

The expression for the service time that we derived considers only the very pessimistic case where sectors are fragmented on the disk in the worst possible way.
In this scenario every access to the disk requires to "pay" $T_{\text{rotation}}$ and $T_{\text{seek}}$.
In many circumstances, this is NOT the case: _files are larger than one sector_ and _stored in a contiguous way_.

---

We can measure the **data locality** $L$ of a disk as the percentage of blocks which do not require rotational or seek delay to be accessed (_assuming that the head is at the previous block of the file to which they belong_).
In this setting the service time becomes:
$$
T_{\text{service}} = (1 - L) (T_{\text{seek}} + T_{\text{rotation}}) + T_{\text{transfer}} + T_{\text{controller}}.
$$

**Remark**: $T_{\text{seek}}$ and $T_{\text{rotation}}$ are the total seek delay and rotational delay respectively for all the sectors that we have to access.

#### Disk scheduling

We want to answer the following problem: suppose that we have a queue of requests to the disk, in which way should we reorder them in order to improve performance?
There are several algorithms which solve this problem:
- **First Come, First Served** (**FCFS**);
- **Shortest Seek Time First** (**SSTF**);
- **SCAN**;
- **C-SCAN**, **C-LOOK**, etc. .

##### First Come, First Served

FCFS is the most basic scheduler: it serves the requests in order without performing any optimization. It spends a lot of time seeking.

---

##### Shortest Seek Time First

SSTF minimizes the total seek time by accommodating the request in the queue whose initial block (to be read or written) is the closest w.r.t. the current position of the head.

**Pros**: it is _optimal_ and easily implemented.

**Cons**: it is prone to _starvation_.

##### SCAN

The head _sweeps_ across the disk (going from the first sector to the last and then from the last to the first) serving requests as their first block (_to be read or written_) is encountered.

**Pros**: it has _good performance_, and _NO starvation_.

**Cons**: average access times are higher for requests at high and low addresses.

##### Circular-SCAN (C-SCAN)

It is _like SCAN_ but serves requests only when moving from the first sector to the last. That is, once it reaches the last sector, it goes back to the first without serving any request.

**Pros**: it is fairer than SCAN (_no issues with requests at high and low addresses_).

---

**Cons**: it has worse performance than SCAN.

##### C-LOOK

It is a variant of C-SCAN in which the head, instead of reaching the last sector, stops after having served the request with the initial block with highest address, and, instead of going back to the first sector (_without serving any request_), it stops when it reaches the initial block of the requests at the lowest address.

